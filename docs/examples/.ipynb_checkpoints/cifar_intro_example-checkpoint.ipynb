{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pxenopoulos/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10, cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "batch_size = 32\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Keep airplanes (0) and ships (8) from CIFAR-10\n",
    "airplanes = y_train == [0]\n",
    "ships = y_train == [8]\n",
    "indices = airplanes + ships\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train = x_train[indx_to_use]\n",
    "y_train = y_train[indx_to_use]\n",
    "\n",
    "y_train = (y_train == 8).astype(int)\n",
    "y_train = np.concatenate(y_train).ravel().tolist()\n",
    "\n",
    "# Ships are now 1, airplanes are 0\n",
    "\n",
    "# keep cloud (50) and sea (54) from CIFAR-100\n",
    "(x_train_concept, y_train_concept), (x_test_concept, y_test_concept) = cifar100.load_data()\n",
    "\n",
    "other = y_train_concept == [47]\n",
    "concept = y_train_concept == [54]\n",
    "indices = other + concept\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train_concept = x_train_concept[indx_to_use]\n",
    "y_train_concept = y_train_concept[indx_to_use]\n",
    "y_train_concept = (y_train_concept == 54).astype(int)\n",
    "y_train_concept = np.concatenate(y_train_concept).ravel().tolist()\n",
    "# Sea is now 1, clouds are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.5774 - acc: 0.6955\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 0.4266 - acc: 0.8037\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 0.3324 - acc: 0.8609\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# initiate optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "# train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "model.save_weights(\"test_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Utilities for concept activation vectors '''\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def return_split_models(model, layer):\n",
    "    ''' Split a model into model_f and model_h\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model to split\n",
    "    layer : (int)\n",
    "        Integer specifying layer to split model on\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the first part\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the second part\n",
    "    '''\n",
    "    model_f, model_h = Sequential(), Sequential()\n",
    "    for current_layer in range(0, layer+1):\n",
    "        model_f.add(model.layers[current_layer])\n",
    "    # Write input layer for model_h\n",
    "    model_h.add(InputLayer(input_shape=model.layers[layer+1].input_shape[1:]))\n",
    "    for current_layer in range(layer+1, len(model.layers)):\n",
    "        model_h.add(model.layers[current_layer])\n",
    "    return model_f, model_h\n",
    "\n",
    "def train_cav(model_f, x_concept, y_concept):\n",
    "    ''' Return the concept activation vector for the concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cav : (numpy.ndarray)\n",
    "        Concept activation vector\n",
    "    '''\n",
    "    concept_activations = model_f.predict(x_concept)\n",
    "    binary_classifier = Sequential()\n",
    "    binary_classifier.add(Dense(1, input_shape=concept_activations.shape[1:], activation='sigmoid'))\n",
    "    binary_classifier.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    binary_classifier.fit(concept_activations, y_concept, batch_size=32, epochs=20, shuffle=True)\n",
    "    cav = binary_classifier.layers[0].get_weights()[0]\n",
    "    return cav\n",
    "\n",
    "def conceptual_sensitivity(example, model_f, model_h, concept_cav):\n",
    "    ''' Return the conceptual conceptual sensitivity for a given example\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : (numpy.ndarray)\n",
    "        Example to calculate the concept sensitivity (be sure to reshape)\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Second Keras sequential model from return_split_models()\n",
    "    concept_cav : (numpy.ndarray)\n",
    "        Numpy array with the linear concept activation vector for a given concept\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sensitivity : (float32)\n",
    "        Sensitivity for inputted examples\n",
    "    '''\n",
    "    example = np.expand_dims(example, axis = 0)\n",
    "    model_f_activations = model_f.predict(example)[0]\n",
    "    model_f_activations.shape = (1, model_h.input_shape[1])\n",
    "    gradients = k.gradients(model_h.output, model_h.input)\n",
    "    gradient_func = k.function([model_h.input], gradients)\n",
    "    calc_grad = gradient_func([model_f_activations])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    return sensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 275us/step - loss: 2.0944 - acc: 0.7030\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.9146 - acc: 0.8260\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.6117 - acc: 0.8690\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.4510 - acc: 0.9040\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.3897 - acc: 0.9020\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.4266 - acc: 0.9010\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.3040 - acc: 0.9290\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.2124 - acc: 0.9450\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1718 - acc: 0.9520\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.1763 - acc: 0.9520\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1311 - acc: 0.9610\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.1868 - acc: 0.9460\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1350 - acc: 0.9630\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1219 - acc: 0.9670\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0989 - acc: 0.9780\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0772 - acc: 0.9870\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0819 - acc: 0.9850\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0985 - acc: 0.9750\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0730 - acc: 0.9910\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0652 - acc: 0.9950\n"
     ]
    }
   ],
   "source": [
    "model_f, model_h = return_split_models(model, 12)\n",
    "cav_vec = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04048391]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conceptual_sensitivity(x_train[15], model_f, model_h, cav_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcav_score(x_train, y_train, model, layer, x_concept, y_concept):\n",
    "    ''' Returns the TCAV score for the training data to a given concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : (numpy.ndarray)\n",
    "        Training data where the i-th entry as x_train[i] is one example\n",
    "    y_train : (numpy.ndarray)\n",
    "        Training labels where the i-th entry as y_train[i] is one example\n",
    "    model : (keras.engine.sequential.Sequential)\n",
    "        Trained model to use\n",
    "    layer : (int)\n",
    "        Integer specifying layer to split model on\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tcav : (list)\n",
    "        TCAV score for given concept and class\n",
    "    '''\n",
    "    model_f, model_h = return_split_models(model, layer)\n",
    "    concept_cav = train_cav(model_f, x_concept, y_concept)\n",
    "    unique_labels = np.unique(y_train)\n",
    "    tcav = []\n",
    "    for label in unique_labels:\n",
    "        training_subset = x_train[np.array(y_train) == 1]\n",
    "        set_size = training_subset.shape[0]\n",
    "        count_of_sensitivity = 0\n",
    "        for example in training_subset:\n",
    "            sensitivity = conceptual_sensitivity(example, model_f, model_h, concept_cav)\n",
    "            print(sensitivity)\n",
    "            if sensitivity > 0:\n",
    "                count_of_sensitivity = count_of_sensitivity + 1\n",
    "        tcav.append(count_of_sensitivity/set_size)\n",
    "    return tcav\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 785us/step - loss: 1.9364 - acc: 0.7150\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.9694 - acc: 0.8490\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.7314 - acc: 0.8630\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.6311 - acc: 0.8730\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.4928 - acc: 0.9020\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.3235 - acc: 0.9380\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.2849 - acc: 0.9380\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.2821 - acc: 0.9270\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.2100 - acc: 0.9470\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1831 - acc: 0.9560\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1767 - acc: 0.9550\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1512 - acc: 0.9660\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1388 - acc: 0.9610\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1345 - acc: 0.9710\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0972 - acc: 0.9780\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0924 - acc: 0.9810\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0815 - acc: 0.9860\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0792 - acc: 0.9880\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0689 - acc: 0.9910\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0668 - acc: 0.9920\n",
      "[[0.0146194]]\n",
      "[[0.00352947]]\n",
      "[[0.0014952]]\n",
      "[[0.00019256]]\n",
      "[[-0.02676477]]\n",
      "[[0.00328797]]\n",
      "[[-0.00978979]]\n",
      "[[-0.00032704]]\n",
      "[[0.00346274]]\n",
      "[[0.00305338]]\n",
      "[[0.00066273]]\n",
      "[[0.00063893]]\n",
      "[[-0.00146897]]\n",
      "[[0.00090129]]\n",
      "[[-0.01142519]]\n",
      "[[0.0005411]]\n",
      "[[2.464006e-05]]\n",
      "[[0.00029289]]\n",
      "[[0.00612448]]\n",
      "[[0.00765407]]\n",
      "[[0.00019194]]\n",
      "[[0.00120445]]\n",
      "[[-0.00269957]]\n",
      "[[0.00077988]]\n",
      "[[0.00039257]]\n",
      "[[0.00326792]]\n",
      "[[0.00642854]]\n",
      "[[0.00089102]]\n",
      "[[0.00041118]]\n",
      "[[-0.00058731]]\n",
      "[[-0.01170555]]\n",
      "[[-0.00972312]]\n",
      "[[0.00320987]]\n",
      "[[0.0017503]]\n",
      "[[3.4967852e-06]]\n",
      "[[-0.02242381]]\n",
      "[[0.01763127]]\n",
      "[[-0.025025]]\n",
      "[[-0.01776994]]\n",
      "[[0.00109335]]\n",
      "[[0.00022768]]\n",
      "[[0.00486347]]\n",
      "[[0.00439741]]\n",
      "[[-0.00120438]]\n",
      "[[0.0031899]]\n",
      "[[0.0001403]]\n",
      "[[0.00111339]]\n",
      "[[0.00040335]]\n",
      "[[0.00042626]]\n",
      "[[0.00129886]]\n",
      "[[0.0003845]]\n",
      "[[6.621791e-05]]\n",
      "[[-0.02158402]]\n",
      "[[0.00077591]]\n",
      "[[-0.02915468]]\n",
      "[[0.00250678]]\n",
      "[[0.00172527]]\n",
      "[[0.00131135]]\n",
      "[[-0.01017236]]\n",
      "[[-0.01124327]]\n",
      "[[0.00481036]]\n",
      "[[-0.00226323]]\n",
      "[[0.00173789]]\n",
      "[[-0.00511498]]\n",
      "[[0.00497527]]\n",
      "[[0.01079579]]\n",
      "[[0.00392046]]\n",
      "[[0.00025019]]\n",
      "[[0.00058969]]\n",
      "[[0.00026136]]\n",
      "[[-0.01157652]]\n",
      "[[0.00563973]]\n",
      "[[0.00358611]]\n",
      "[[-0.00044927]]\n",
      "[[0.00270463]]\n",
      "[[-0.01741048]]\n",
      "[[0.00280939]]\n",
      "[[0.00092041]]\n",
      "[[0.0095834]]\n",
      "[[-0.01358533]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-ce89ce8649b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtcav_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_concept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_concept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-fb93ff476238>\u001b[0m in \u001b[0;36mtcav_score\u001b[0;34m(x_train, y_train, model, layer, x_concept, y_concept)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mcount_of_sensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_subset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0msensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconceptual_sensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcept_cav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msensitivity\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-7ffb9e1d342e>\u001b[0m in \u001b[0;36mconceptual_sensitivity\u001b[0;34m(example, model_f, model_h, concept_cav)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mgradient_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcalc_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_f_activations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0msensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcept_cav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2633\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2636\u001b[0m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tcav_score(x_train, y_train, model, 12, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cav(model_f, x_concept, y_concept):\n",
    "    ''' Return the concept activation vector for the concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cav : (numpy.ndarray)\n",
    "        Concept activation vector\n",
    "    '''\n",
    "    concept_activations = model_f.predict(x_concept)\n",
    "    binary_classifier = Sequential()\n",
    "    binary_classifier.add(Dense(1, input_shape=concept_activations.shape[1:], activation='sigmoid'))\n",
    "    binary_classifier.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    binary_classifier.fit(concept_activations, y_concept, batch_size=32, epochs=20, shuffle=True)\n",
    "    cav = binary_classifier.layers[0].get_weights()[0]\n",
    "    return cav\n",
    "\n",
    "concept_cav = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conceptual_sensitivity(example, model_f, model_h, concept_cav):\n",
    "    ''' Return the conceptual conceptual sensitivity for a given example\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : (numpy.ndarray)\n",
    "        Example to calculate the concept sensitivity (be sure to reshape)\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Second Keras sequential model from return_split_models()\n",
    "    concept_cav : (numpy.ndarray)\n",
    "        Numpy array with the linear concept activation vector for a given concept\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sensitivity : (float32)\n",
    "        Sensitivity for inputted examples\n",
    "    '''\n",
    "    model_f_activations = model_f.predict(example)[0]\n",
    "    gradients = k.gradients(model_h.output, model_h.input)\n",
    "    gradient_func = k.function([model_h.input], gradients)\n",
    "    calc_grad = gradient_func([model_f_activations])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    return sensitivity\n",
    "\n",
    "conceptual_sensitivity(x_train[0], model_f, model_h, concept_cav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f = Sequential()\n",
    "model_f.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:], weights = model.layers[0].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(Conv2D(32, (3, 3), weights = model.layers[2].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_f.add(Dropout(0.25))\n",
    "\n",
    "model_f.add(Conv2D(64, (3, 3), padding='same', weights = model.layers[6].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(Conv2D(64, (3, 3), weights = model.layers[8].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_f.add(Flatten())\n",
    "\n",
    "acts = model_f.predict(x_train_concept)\n",
    "\n",
    "model_h = Sequential()\n",
    "model_h.add(Dense(512, input_shape=acts.shape[1:], weights = model.layers[13].get_weights()))\n",
    "model_h.add(Activation('relu'))\n",
    "model_h.add(Dropout(0.5))\n",
    "model_h.add(Dense(1, weights = model.layers[16].get_weights()))\n",
    "model_h.add(Activation('sigmoid'))\n",
    "\n",
    "concept_cav = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = x_train[np.array(y_train) == 1]\n",
    "\n",
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)\n",
    "pos_sens = 0\n",
    "list_sens = []\n",
    "for train_ex in training_subset:\n",
    "    example = train_ex.reshape((1, 32, 32, 3))\n",
    "    example_f = model_f.predict(example)[0].reshape((1,2304))\n",
    "    calc_grad = gradient_func([example_f])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    list_sens.append(sensitivity)\n",
    "    if sensitivity > 0:\n",
    "        pos_sens = pos_sens + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns, numpy as np\n",
    "ax = sns.distplot(list_sens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = x_train[np.array(y_train) == 0]\n",
    "i = 777\n",
    "example = training_subset[i].reshape((1, 32, 32, 3))\n",
    "example_f = model_f.predict(example)[0].reshape((1,2304))\n",
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)\n",
    "calc_grad = gradient_func([example_f])[0]\n",
    "sensitivity = np.dot(calc_grad, concept_cav)\n",
    "sensitivity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
