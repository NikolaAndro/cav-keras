{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pxenopoulos/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10, cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "batch_size = 32\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Keep airplanes (0) and ships (8) from CIFAR-10\n",
    "airplanes = y_train == [0]\n",
    "ships = y_train == [8]\n",
    "indices = airplanes + ships\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train = x_train[indx_to_use]\n",
    "y_train = y_train[indx_to_use]\n",
    "\n",
    "y_train = (y_train == 8).astype(int)\n",
    "y_train = np.concatenate(y_train).ravel().tolist()\n",
    "\n",
    "# Ships are now 1, airplanes are 0\n",
    "\n",
    "# keep cloud (50) and sea (54) from CIFAR-100\n",
    "(x_train_concept, y_train_concept), (x_test_concept, y_test_concept) = cifar100.load_data()\n",
    "\n",
    "other = y_train_concept == [47]\n",
    "concept = y_train_concept == [54]\n",
    "indices = other + concept\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train_concept = x_train_concept[indx_to_use]\n",
    "y_train_concept = y_train_concept[indx_to_use]\n",
    "y_train_concept = (y_train_concept == 54).astype(int)\n",
    "y_train_concept = np.concatenate(y_train_concept).ravel().tolist()\n",
    "# Sea is now 1, clouds are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.5800 - acc: 0.6929\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.4200 - acc: 0.8116\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.3319 - acc: 0.8581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133d556a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# initiate optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "# train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Utilities for concept activation vectors '''\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def return_split_models(model, layer):\n",
    "    ''' Split a model into model_f and model_h\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model to split\n",
    "    layer : (int)\n",
    "        Integer specifying layer to split model on\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the first part\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the second part\n",
    "    '''\n",
    "    model_f, model_h = Sequential(), Sequential()\n",
    "    for current_layer in range(0, layer+1):\n",
    "        model_f.add(model.layers[current_layer])\n",
    "    # Write input layer for model_h\n",
    "    model_h.add(InputLayer(input_shape=model.layers[layer+1].input_shape[1:]))\n",
    "    for current_layer in range(layer+1, len(model.layers)):\n",
    "        model_h.add(model.layers[current_layer])\n",
    "    return model_f, model_h\n",
    "\n",
    "def train_cav(model_f, x_concept, y_concept):\n",
    "    ''' Return the concept activation vector for the concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cav : (numpy.ndarray)\n",
    "        Concept activation vector\n",
    "    '''\n",
    "    concept_activations = model_f.predict(x_concept)\n",
    "    binary_classifier = Sequential()\n",
    "    binary_classifier.add(Dense(1, input_shape=concept_activations.shape[1:], activation='sigmoid'))\n",
    "    binary_classifier.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    binary_classifier.fit(concept_activations, y_concept, batch_size=32, epochs=20, shuffle=True)\n",
    "    cav = binary_classifier.layers[0].get_weights()[0]\n",
    "    return cav\n",
    "\n",
    "def conceptual_sensitivity(example, model_f, model_h, concept_cav):\n",
    "    ''' Return the conceptual conceptual sensitivity for a given example\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : (numpy.ndarray)\n",
    "        Example to calculate the concept sensitivity (be sure to reshape)\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Second Keras sequential model from return_split_models()\n",
    "    concept_cav : (numpy.ndarray)\n",
    "        Numpy array with the linear concept activation vector for a given concept\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sensitivity : (float32)\n",
    "        Sensitivity for inputted examples\n",
    "    '''\n",
    "    example = np.expand_dims(example, axis = 0)\n",
    "    model_f_activations = model_f.predict(example)[0]\n",
    "    model_f_activations.shape = (1, model_h.input_shape[1])\n",
    "    gradients = k.gradients(model_h.output, model_h.input)\n",
    "    gradient_func = k.function([model_h.input], gradients)\n",
    "    calc_grad = gradient_func([model_f_activations])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    return sensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 193us/step - loss: 2.9566 - acc: 0.6460\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 1.1557 - acc: 0.8280\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.7798 - acc: 0.8650\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.5377 - acc: 0.8930\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.4439 - acc: 0.9040\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.3437 - acc: 0.9250\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.2405 - acc: 0.9410\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.2710 - acc: 0.9370\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1787 - acc: 0.9630\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1548 - acc: 0.9730\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1149 - acc: 0.9740\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1191 - acc: 0.9670\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0945 - acc: 0.9800\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0589 - acc: 0.9880\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0752 - acc: 0.9750\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0527 - acc: 0.9870\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0366 - acc: 0.9910\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0286 - acc: 0.9930\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0211 - acc: 0.9960\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0255 - acc: 0.9950\n"
     ]
    }
   ],
   "source": [
    "model_f, model_h = return_split_models(model, 12)\n",
    "cav_vec = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f_activations = model_f.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_grad = gradient_func([model_f_activations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_grad = gradient_func([model_f_activations])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.dot(calc_grad, cav_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1216892"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcav_score(x_train, y_train, model, layer, x_concept, y_concept):\n",
    "    ''' Returns the TCAV score for the training data to a given concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : (numpy.ndarray)\n",
    "        Training data where the i-th entry as x_train[i] is one example\n",
    "    y_train : (numpy.ndarray)\n",
    "        Training labels where the i-th entry as y_train[i] is one example\n",
    "    model : (keras.engine.sequential.Sequential)\n",
    "        Trained model to use\n",
    "    layer : (int)\n",
    "        Integer specifying layer to split model on\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tcav : (list)\n",
    "        TCAV score for given concept and class\n",
    "    '''\n",
    "    model_f, model_h = return_split_models(model, layer)\n",
    "    concept_cav = train_cav(model_f, x_concept, y_concept)\n",
    "    unique_labels = np.unique(y_train)\n",
    "    tcav = []\n",
    "    for label in unique_labels:\n",
    "        training_subset = x_train[np.array(y_train) == 1]\n",
    "        set_size = training_subset.shape[0]\n",
    "        count_of_sensitivity = 0\n",
    "        for example in training_subset:\n",
    "            sensitivity = conceptual_sensitivity(example, model_f, model_h, concept_cav)\n",
    "            print(sensitivity)\n",
    "            if sensitivity > 0:\n",
    "                count_of_sensitivity = count_of_sensitivity + 1\n",
    "        tcav.append(count_of_sensitivity/set_size)\n",
    "    return tcav\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 225us/step - loss: 1.8043 - acc: 0.7350\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.8831 - acc: 0.8470\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.5363 - acc: 0.8890\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.3631 - acc: 0.9100\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.3518 - acc: 0.9150\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.2934 - acc: 0.9260\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1880 - acc: 0.9470\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1399 - acc: 0.9560\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.1477 - acc: 0.9560\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1059 - acc: 0.9650\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0872 - acc: 0.9670\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0657 - acc: 0.9810\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0490 - acc: 0.9820\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0593 - acc: 0.9730\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0522 - acc: 0.9820\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0256 - acc: 0.9910\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0253 - acc: 0.9910\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0600 - acc: 0.9780\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0536 - acc: 0.9850\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0295 - acc: 0.9910\n",
      "[[-0.03728578]]\n",
      "[[-0.00250733]]\n",
      "[[-0.04305428]]\n",
      "[[-0.00483093]]\n",
      "[[-0.036454]]\n",
      "[[-0.04115237]]\n",
      "[[-0.06001277]]\n",
      "[[-0.01180858]]\n",
      "[[-0.01553534]]\n",
      "[[-0.04622943]]\n",
      "[[-0.00784498]]\n",
      "[[-0.01018857]]\n",
      "[[-0.04193909]]\n",
      "[[-0.00289689]]\n",
      "[[-0.05575181]]\n",
      "[[-0.00140556]]\n",
      "[[-0.00195391]]\n",
      "[[-0.00048382]]\n",
      "[[-0.0655925]]\n",
      "[[-0.02873251]]\n",
      "[[-0.04046832]]\n",
      "[[-0.00739403]]\n",
      "[[-0.04186008]]\n",
      "[[-0.00936851]]\n",
      "[[-0.00214168]]\n",
      "[[-0.05552054]]\n",
      "[[-0.00783625]]\n",
      "[[-0.00364851]]\n",
      "[[-0.06330016]]\n",
      "[[-0.01566035]]\n",
      "[[-0.02559472]]\n",
      "[[-0.02646149]]\n",
      "[[-0.04818578]]\n",
      "[[-0.07494879]]\n",
      "[[-3.531226e-05]]\n",
      "[[-0.07470469]]\n",
      "[[-0.04512097]]\n",
      "[[-0.06878021]]\n",
      "[[-0.05956537]]\n",
      "[[-0.01460634]]\n",
      "[[-0.00114365]]\n",
      "[[-0.01464209]]\n",
      "[[-0.03851275]]\n",
      "[[-0.05446799]]\n",
      "[[-0.03562427]]\n",
      "[[-0.02440583]]\n",
      "[[-0.01359007]]\n",
      "[[-0.00321153]]\n",
      "[[-0.01050436]]\n",
      "[[-0.00680463]]\n",
      "[[-0.01479015]]\n",
      "[[-0.00211393]]\n",
      "[[-0.05444082]]\n",
      "[[-0.00885346]]\n",
      "[[-0.05835705]]\n",
      "[[-0.04146229]]\n",
      "[[-0.00380822]]\n",
      "[[-0.05058576]]\n",
      "[[-0.02367545]]\n",
      "[[-0.08161484]]\n",
      "[[-0.06088857]]\n",
      "[[-0.03763345]]\n",
      "[[-0.0041288]]\n",
      "[[-0.06892206]]\n",
      "[[-0.00914434]]\n",
      "[[-0.04769775]]\n",
      "[[-0.02345451]]\n",
      "[[-0.00487149]]\n",
      "[[-0.05730565]]\n",
      "[[-0.02510143]]\n",
      "[[-0.07213459]]\n",
      "[[-0.0357806]]\n",
      "[[-0.03218316]]\n",
      "[[-0.05146565]]\n",
      "[[-0.05714566]]\n",
      "[[-0.07199909]]\n",
      "[[-0.07115717]]\n",
      "[[-0.0123199]]\n",
      "[[-0.07410556]]\n",
      "[[-0.06705345]]\n",
      "[[-0.00538303]]\n",
      "[[-0.03373567]]\n",
      "[[-0.04744682]]\n",
      "[[-0.00811517]]\n",
      "[[-0.02059648]]\n",
      "[[-0.01906748]]\n",
      "[[-0.00491862]]\n",
      "[[-0.01108204]]\n",
      "[[-0.00710064]]\n",
      "[[-0.05839442]]\n",
      "[[-0.01204202]]\n",
      "[[-0.0424429]]\n",
      "[[-0.02115521]]\n",
      "[[-0.06215763]]\n",
      "[[-0.0070896]]\n",
      "[[-0.04405161]]\n",
      "[[-0.04939788]]\n",
      "[[-0.00241028]]\n",
      "[[-0.03963917]]\n",
      "[[-0.00268824]]\n",
      "[[-0.0130218]]\n",
      "[[-0.00771673]]\n",
      "[[-0.04759955]]\n",
      "[[-0.00123042]]\n",
      "[[-0.01278482]]\n",
      "[[-0.08087689]]\n",
      "[[-0.00925883]]\n",
      "[[-0.04519146]]\n",
      "[[-0.04739743]]\n",
      "[[-0.00053919]]\n",
      "[[-0.00806577]]\n",
      "[[-0.01675526]]\n",
      "[[-0.02397748]]\n",
      "[[-0.00662635]]\n",
      "[[-0.00579664]]\n",
      "[[-0.02516403]]\n",
      "[[-0.06564109]]\n",
      "[[-0.00213087]]\n",
      "[[-0.05845035]]\n",
      "[[-0.01194498]]\n",
      "[[-0.01526325]]\n",
      "[[-0.04158989]]\n",
      "[[-0.00137073]]\n",
      "[[-0.01779019]]\n",
      "[[-0.04690525]]\n",
      "[[-0.00948265]]\n",
      "[[-0.00394285]]\n",
      "[[-0.06703098]]\n",
      "[[-0.01391041]]\n",
      "[[-0.07343125]]\n",
      "[[-0.00929887]]\n",
      "[[-0.05357596]]\n",
      "[[-0.02897825]]\n",
      "[[-0.06851624]]\n",
      "[[-0.0054275]]\n",
      "[[-0.07289308]]\n",
      "[[-0.00345356]]\n",
      "[[-0.08666807]]\n",
      "[[-0.00294241]]\n",
      "[[-0.00952692]]\n",
      "[[-0.00065653]]\n",
      "[[-0.00397168]]\n",
      "[[-0.01857694]]\n",
      "[[-0.01082138]]\n",
      "[[-0.01183475]]\n",
      "[[-0.04748058]]\n",
      "[[-0.05795801]]\n",
      "[[-0.00047292]]\n",
      "[[-0.02426484]]\n",
      "[[-0.00365889]]\n",
      "[[-0.01301927]]\n",
      "[[-0.0140154]]\n",
      "[[-0.00092035]]\n",
      "[[-0.07429859]]\n",
      "[[-0.02450804]]\n",
      "[[-0.01614989]]\n",
      "[[-0.03680096]]\n",
      "[[-0.05885737]]\n",
      "[[-0.00369419]]\n",
      "[[-0.00656801]]\n",
      "[[-0.05523177]]\n",
      "[[-0.06125389]]\n",
      "[[-0.00211533]]\n",
      "[[-0.05627283]]\n",
      "[[-0.05848508]]\n",
      "[[-0.07776865]]\n",
      "[[-0.06441746]]\n",
      "[[-0.00354698]]\n",
      "[[-0.06573115]]\n",
      "[[-0.06542734]]\n",
      "[[-0.0200921]]\n",
      "[[-0.02128941]]\n",
      "[[-0.00297377]]\n",
      "[[-0.07490175]]\n",
      "[[-0.01509801]]\n",
      "[[-0.05536316]]\n",
      "[[-0.00388681]]\n",
      "[[-0.05582315]]\n",
      "[[-0.07576272]]\n",
      "[[-0.02458308]]\n",
      "[[-0.01230645]]\n",
      "[[-0.0442374]]\n",
      "[[-0.0180158]]\n",
      "[[-0.0595187]]\n",
      "[[-0.00493914]]\n",
      "[[-0.01185543]]\n",
      "[[-0.08419184]]\n",
      "[[-0.05261095]]\n",
      "[[-0.07691225]]\n",
      "[[-0.00067418]]\n",
      "[[-0.00642243]]\n",
      "[[-0.00729198]]\n",
      "[[-0.04971699]]\n",
      "[[-0.06434878]]\n",
      "[[-0.07709464]]\n",
      "[[-0.06675737]]\n",
      "[[-0.00562141]]\n",
      "[[-0.05226173]]\n",
      "[[-0.08461154]]\n",
      "[[-0.00596736]]\n",
      "[[-0.00758512]]\n",
      "[[-0.02822283]]\n",
      "[[-0.00556843]]\n",
      "[[-0.00530661]]\n",
      "[[-0.01848245]]\n",
      "[[-0.06012171]]\n",
      "[[-0.0056554]]\n",
      "[[-0.03044679]]\n",
      "[[-0.02638975]]\n",
      "[[-0.04187572]]\n",
      "[[-0.06377267]]\n",
      "[[-0.0093278]]\n",
      "[[-0.00482375]]\n",
      "[[-0.00448472]]\n",
      "[[-0.04899732]]\n",
      "[[-0.06095847]]\n",
      "[[-0.00742321]]\n",
      "[[-0.00502905]]\n",
      "[[-0.03516129]]\n",
      "[[-0.04093793]]\n",
      "[[-0.05453447]]\n",
      "[[-0.01740076]]\n",
      "[[-0.0766045]]\n",
      "[[-0.06921511]]\n",
      "[[-0.05956966]]\n",
      "[[-0.00130614]]\n",
      "[[-0.06593906]]\n",
      "[[-0.02479919]]\n",
      "[[-0.03913423]]\n",
      "[[-0.03233748]]\n",
      "[[-0.03697726]]\n",
      "[[-0.06736463]]\n",
      "[[-0.03027975]]\n",
      "[[-0.01702196]]\n",
      "[[-0.08057303]]\n",
      "[[-0.00388225]]\n",
      "[[-0.00966289]]\n",
      "[[-0.06390831]]\n",
      "[[-0.00273073]]\n",
      "[[-0.03427237]]\n",
      "[[-0.075249]]\n",
      "[[-0.00147517]]\n",
      "[[-0.04473107]]\n",
      "[[-0.06572363]]\n",
      "[[-0.05048659]]\n",
      "[[-0.04757759]]\n",
      "[[-0.03174628]]\n",
      "[[-0.00016951]]\n",
      "[[-0.0508228]]\n",
      "[[-0.03480748]]\n",
      "[[-0.00980627]]\n",
      "[[-0.06132943]]\n",
      "[[-0.00238368]]\n",
      "[[-0.05226532]]\n",
      "[[-0.00096778]]\n",
      "[[-0.06517459]]\n",
      "[[-0.04010611]]\n",
      "[[-0.07228634]]\n",
      "[[-0.00057682]]\n",
      "[[-0.05238109]]\n",
      "[[-0.03712854]]\n",
      "[[-0.00092085]]\n",
      "[[-0.01634555]]\n",
      "[[-0.04524145]]\n",
      "[[-0.07967485]]\n",
      "[[-0.0783353]]\n",
      "[[-0.0673023]]\n",
      "[[-0.0637149]]\n",
      "[[-0.06028231]]\n",
      "[[-0.01752465]]\n",
      "[[-0.06694584]]\n",
      "[[-0.05753604]]\n",
      "[[-0.0007176]]\n",
      "[[-0.00070707]]\n",
      "[[-0.0650423]]\n",
      "[[-0.02023428]]\n",
      "[[-0.08826515]]\n",
      "[[-0.00044526]]\n",
      "[[-0.00797108]]\n",
      "[[-0.02264832]]\n",
      "[[-0.05782517]]\n",
      "[[-0.05825347]]\n",
      "[[-0.03319435]]\n",
      "[[-0.01173828]]\n",
      "[[-0.00595628]]\n",
      "[[-0.06117588]]\n",
      "[[-0.05125794]]\n",
      "[[-0.02890366]]\n",
      "[[-0.00452885]]\n",
      "[[-0.00070158]]\n",
      "[[-0.00330232]]\n",
      "[[-0.00114735]]\n",
      "[[-0.03796875]]\n",
      "[[-0.00424867]]\n",
      "[[-0.05444783]]\n",
      "[[-0.0101808]]\n",
      "[[-0.06973511]]\n",
      "[[-0.01445073]]\n",
      "[[-0.05824516]]\n",
      "[[-0.06542643]]\n",
      "[[-0.00459579]]\n",
      "[[-0.03165101]]\n",
      "[[-0.0061942]]\n",
      "[[-0.03164112]]\n",
      "[[-0.00522386]]\n",
      "[[-0.02202048]]\n",
      "[[-0.03110671]]\n",
      "[[-0.03463016]]\n",
      "[[-0.0571594]]\n",
      "[[-0.01985821]]\n",
      "[[-0.02788719]]\n",
      "[[-0.01183252]]\n",
      "[[-0.05181639]]\n",
      "[[-0.05904319]]\n",
      "[[-0.00140491]]\n",
      "[[-0.05075248]]\n",
      "[[-0.02770047]]\n",
      "[[-9.919451e-05]]\n",
      "[[-0.06164099]]\n",
      "[[-0.00053344]]\n",
      "[[-0.01781742]]\n",
      "[[-0.01382877]]\n",
      "[[-0.03401527]]\n",
      "[[-0.03565116]]\n",
      "[[-0.06702606]]\n",
      "[[-0.06941389]]\n",
      "[[-0.06155164]]\n",
      "[[-0.03411956]]\n",
      "[[-0.00995118]]\n",
      "[[-0.06140145]]\n",
      "[[-0.05537982]]\n",
      "[[-0.04529148]]\n",
      "[[-0.06554823]]\n",
      "[[-0.06617224]]\n",
      "[[-0.01129631]]\n",
      "[[-0.00516972]]\n",
      "[[-0.00775741]]\n",
      "[[-0.04389422]]\n",
      "[[-0.05339534]]\n",
      "[[-0.0841348]]\n",
      "[[-0.00143941]]\n",
      "[[-0.01181314]]\n",
      "[[-0.05394412]]\n",
      "[[-0.02312797]]\n",
      "[[-0.01172975]]\n",
      "[[-0.03993642]]\n",
      "[[-0.02614553]]\n",
      "[[-0.05797799]]\n",
      "[[-0.066209]]\n",
      "[[-0.0031548]]\n",
      "[[-0.04939724]]\n",
      "[[-0.00578215]]\n",
      "[[-0.04439681]]\n",
      "[[-0.00522921]]\n",
      "[[-0.01926111]]\n",
      "[[-0.03634305]]\n",
      "[[-0.05624596]]\n",
      "[[-0.04926548]]\n",
      "[[-0.01285511]]\n",
      "[[-0.00202189]]\n",
      "[[-0.00489428]]\n",
      "[[-0.07006846]]\n",
      "[[-0.0204777]]\n",
      "[[-0.0009944]]\n",
      "[[-0.01899526]]\n",
      "[[-0.04688977]]\n",
      "[[-0.05858917]]\n",
      "[[-0.05944072]]\n",
      "[[-0.04076339]]\n",
      "[[-0.06505213]]\n",
      "[[-0.00996841]]\n",
      "[[-0.02291725]]\n",
      "[[-0.03163529]]\n",
      "[[-0.02633044]]\n",
      "[[-0.01074004]]\n",
      "[[-0.03423947]]\n",
      "[[-0.0020104]]\n",
      "[[-4.600212e-05]]\n",
      "[[-0.08006351]]\n",
      "[[-0.07462887]]\n",
      "[[-0.00073348]]\n",
      "[[-0.06903864]]\n",
      "[[-0.00167323]]\n",
      "[[-0.00579309]]\n",
      "[[-0.02706878]]\n",
      "[[-0.03152245]]\n",
      "[[-0.07624101]]\n",
      "[[-0.06024633]]\n",
      "[[-0.02526081]]\n",
      "[[-0.04167117]]\n",
      "[[-0.00199636]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05808521]]\n",
      "[[-0.00345427]]\n",
      "[[-0.05532186]]\n",
      "[[-0.0048513]]\n",
      "[[-0.07762858]]\n",
      "[[-0.05822182]]\n",
      "[[-0.04265228]]\n",
      "[[-0.00575652]]\n",
      "[[-0.07765621]]\n",
      "[[-0.02003738]]\n",
      "[[-0.04840364]]\n",
      "[[-0.01655737]]\n",
      "[[-0.01826249]]\n",
      "[[-0.04173943]]\n",
      "[[-0.00204695]]\n",
      "[[-0.05426455]]\n",
      "[[-0.0303661]]\n",
      "[[-0.0166532]]\n",
      "[[-0.06139692]]\n",
      "[[-0.00239196]]\n",
      "[[-0.0421953]]\n",
      "[[-0.00667992]]\n",
      "[[-0.0810294]]\n"
     ]
    }
   ],
   "source": [
    "tcav_score(x_train, y_train, model, 12, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cav(model_f, x_concept, y_concept):\n",
    "    ''' Return the concept activation vector for the concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cav : (numpy.ndarray)\n",
    "        Concept activation vector\n",
    "    '''\n",
    "    concept_activations = model_f.predict(x_concept)\n",
    "    binary_classifier = Sequential()\n",
    "    binary_classifier.add(Dense(1, input_shape=concept_activations.shape[1:], activation='sigmoid'))\n",
    "    binary_classifier.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    binary_classifier.fit(concept_activations, y_concept, batch_size=32, epochs=20, shuffle=True)\n",
    "    cav = binary_classifier.layers[0].get_weights()[0]\n",
    "    return cav\n",
    "\n",
    "concept_cav = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conceptual_sensitivity(example, model_f, model_h, concept_cav):\n",
    "    ''' Return the conceptual conceptual sensitivity for a given example\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : (numpy.ndarray)\n",
    "        Example to calculate the concept sensitivity (be sure to reshape)\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Second Keras sequential model from return_split_models()\n",
    "    concept_cav : (numpy.ndarray)\n",
    "        Numpy array with the linear concept activation vector for a given concept\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sensitivity : (float32)\n",
    "        Sensitivity for inputted examples\n",
    "    '''\n",
    "    model_f_activations = model_f.predict(example)[0]\n",
    "    gradients = k.gradients(model_h.output, model_h.input)\n",
    "    gradient_func = k.function([model_h.input], gradients)\n",
    "    calc_grad = gradient_func([model_f_activations])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    return sensitivity\n",
    "\n",
    "conceptual_sensitivity(x_train[0], model_f, model_h, concept_cav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f = Sequential()\n",
    "model_f.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:], weights = model.layers[0].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(Conv2D(32, (3, 3), weights = model.layers[2].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_f.add(Dropout(0.25))\n",
    "\n",
    "model_f.add(Conv2D(64, (3, 3), padding='same', weights = model.layers[6].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(Conv2D(64, (3, 3), weights = model.layers[8].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_f.add(Flatten())\n",
    "\n",
    "acts = model_f.predict(x_train_concept)\n",
    "\n",
    "model_h = Sequential()\n",
    "model_h.add(Dense(512, input_shape=acts.shape[1:], weights = model.layers[13].get_weights()))\n",
    "model_h.add(Activation('relu'))\n",
    "model_h.add(Dropout(0.5))\n",
    "model_h.add(Dense(1, weights = model.layers[16].get_weights()))\n",
    "model_h.add(Activation('sigmoid'))\n",
    "\n",
    "concept_cav = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = x_train[np.array(y_train) == 1]\n",
    "\n",
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)\n",
    "pos_sens = 0\n",
    "list_sens = []\n",
    "for train_ex in training_subset:\n",
    "    example = train_ex.reshape((1, 32, 32, 3))\n",
    "    example_f = model_f.predict(example)[0].reshape((1,2304))\n",
    "    calc_grad = gradient_func([example_f])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    list_sens.append(sensitivity)\n",
    "    if sensitivity > 0:\n",
    "        pos_sens = pos_sens + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns, numpy as np\n",
    "ax = sns.distplot(list_sens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = x_train[np.array(y_train) == 0]\n",
    "i = 777\n",
    "example = training_subset[i].reshape((1, 32, 32, 3))\n",
    "example_f = model_f.predict(example)[0].reshape((1,2304))\n",
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)\n",
    "calc_grad = gradient_func([example_f])[0]\n",
    "sensitivity = np.dot(calc_grad, concept_cav)\n",
    "sensitivity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
