{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Activation Vectors (CAVs) example on CIFAR data\n",
    "### Peter Xenopoulos\n",
    "\n",
    "In this workbook, we will go over how to use CAVs on some popular image data -- the CIFAR datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar100, cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "from cav.cav import *\n",
    "\n",
    "np.random.seed(1996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must import some images from CIFAR-10. We will import the _ships_ and the _dog_ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Keep airplanes (5) and ships (8) from CIFAR-10\n",
    "ships = y_train == [8]\n",
    "other = y_train == [2]\n",
    "indices = ships + other\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train = x_train[indx_to_use]\n",
    "y_train = y_train[indx_to_use]\n",
    "\n",
    "y_train = (y_train == 8).astype(int)\n",
    "y_train = np.concatenate(y_train).ravel().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13a7e3940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1325b7a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(x_train[0])\n",
    "axarr[1].imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must specify a _concept_. This is a certain idea we want to capture from our pictures. Let's say we are interested in the concept of the _sea_. Let's load in CIFAR-100 to get some pictures of the sea and some random counterexample, which we'll just make apples for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_concept, y_train_concept), (x_test_concept, y_test_concept) = cifar100.load_data()\n",
    "\n",
    "# keep sea (54) from CIFAR-100\n",
    "concept = y_train_concept == [71]\n",
    "indices = concept\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train_concept = x_train_concept[indx_to_use]\n",
    "y_train_concept = [1] * 500\n",
    "y_train_concept.append([0] * 500)\n",
    "\n",
    "counterexamples = create_counterexamples(n = 500, height = 32, width = 32, channels = 3)\n",
    "x_train_concept = np.append(x_train_concept, counterexamples, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13a9525f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13a7ff940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(x_train_concept[0])\n",
    "axarr[1].imshow(x_train_concept[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we must train our initial model. We do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.3410 - acc: 0.8479\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 0.2270 - acc: 0.9097\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 0.1949 - acc: 0.9264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13aaac0b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameters\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# initiate optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "# train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,246,241\n",
      "Trainable params: 1,246,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we split our model on a given layer. We can see that the last convolution layer is layer 8, but in order for our method to work, we need to include the activations and pooling and flattening. So, we will split on layer 12. Then, we train a binary classifier on our concepts. This will produce our concept activation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "y_train_concept = [1] * 500\n",
    "y_train_concept.append([0] * 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6cd01b22a730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_split_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcav_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_concept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_concept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/cav-keras/cav/cav.py\u001b[0m in \u001b[0;36mtrain_cav\u001b[0;34m(model_f, x_concept, y_concept)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mbinary_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcept_activations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mbinary_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mbinary_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcept_activations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_concept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mcav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mindices_for_conversion_to_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model_f, model_h = return_split_models(model, 12)\n",
    "cav_vec = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see the concept activation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cav_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each original training example, we calculate the sensitivity to the concept using our `cav_vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivities = conceptual_sensitivity(x_train, model_f, model_h, cav_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f, model_h = return_split_models(model, 12)\n",
    "concept_cav = train_cav(model_f, x_train_concept, y_train_concept)\n",
    "unique_labels = np.unique(y_train)\n",
    "tcav = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset[0:1].shape\n",
    "conceptual_sensitivity(training_subset[0:1], model_f, model_h, cav_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = x_train[np.array(y_train) == 1]\n",
    "set_size = training_subset.shape[0]\n",
    "count_of_sensitivity = 0\n",
    "for example in training_subset:\n",
    "    #sensitivity = conceptual_sensitivity(example, model_f, model_h, concept_cav)\n",
    "    #print(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training_subset[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in unique_labels:\n",
    "    training_subset = x_train[np.array(y_train) == 1]\n",
    "    set_size = training_subset.shape[0]\n",
    "    count_of_sensitivity = 0\n",
    "    for example in training_subset:\n",
    "        sensitivity = conceptual_sensitivity(example, model_f, model_h, concept_cav)\n",
    "        if sensitivity > 0:\n",
    "            count_of_sensitivity = count_of_sensitivity + 1\n",
    "    tcav.append(count_of_sensitivity/set_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# below is test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "batch_size = 32\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Keep airplanes (0) and ships (8) from CIFAR-10\n",
    "airplanes = y_train == [0]\n",
    "ships = y_train == [8]\n",
    "indices = airplanes + ships\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train = x_train[indx_to_use]\n",
    "y_train = y_train[indx_to_use]\n",
    "\n",
    "y_train = (y_train == 8).astype(int)\n",
    "y_train = np.concatenate(y_train).ravel().tolist()\n",
    "\n",
    "# Ships are now 1, airplanes are 0\n",
    "\n",
    "# keep cloud (50) and sea (54) from CIFAR-100\n",
    "(x_train_concept, y_train_concept), (x_test_concept, y_test_concept) = cifar100.load_data()\n",
    "\n",
    "other = y_train_concept == [47]\n",
    "concept = y_train_concept == [54]\n",
    "indices = other + concept\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train_concept = x_train_concept[indx_to_use]\n",
    "y_train_concept = y_train_concept[indx_to_use]\n",
    "y_train_concept = (y_train_concept == 54).astype(int)\n",
    "y_train_concept = np.concatenate(y_train_concept).ravel().tolist()\n",
    "# Sea is now 1, clouds are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# initiate optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "# train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Utilities for concept activation vectors '''\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def return_split_models(model, layer):\n",
    "    ''' Split a model into model_f and model_h\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model to split\n",
    "    layer : (int)\n",
    "        Integer specifying layer to split model on\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the first part\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the second part\n",
    "    '''\n",
    "    model_f, model_h = Sequential(), Sequential()\n",
    "    for current_layer in range(0, layer+1):\n",
    "        model_f.add(model.layers[current_layer])\n",
    "    # Write input layer for model_h\n",
    "    model_h.add(InputLayer(input_shape=model.layers[layer+1].input_shape[1:]))\n",
    "    for current_layer in range(layer+1, len(model.layers)):\n",
    "        model_h.add(model.layers[current_layer])\n",
    "    return model_f, model_h\n",
    "\n",
    "def train_cav(model_f, x_concept, y_concept):\n",
    "    ''' Return the concept activation vector for the concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cav : (numpy.ndarray)\n",
    "        Concept activation vector\n",
    "    '''\n",
    "    concept_activations = model_f.predict(x_concept)\n",
    "    binary_classifier = Sequential()\n",
    "    binary_classifier.add(Dense(1, input_shape=concept_activations.shape[1:], activation='sigmoid'))\n",
    "    binary_classifier.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    binary_classifier.fit(concept_activations, y_concept, batch_size=32, epochs=20, shuffle=True)\n",
    "    cav = binary_classifier.layers[0].get_weights()[0]\n",
    "    return cav\n",
    "\n",
    "def conceptual_sensitivity(example, model_f, model_h, concept_cav):\n",
    "    ''' Return the conceptual conceptual sensitivity for a given example\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : (numpy.ndarray)\n",
    "        Example to calculate the concept sensitivity (be sure to reshape)\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Second Keras sequential model from return_split_models()\n",
    "    concept_cav : (numpy.ndarray)\n",
    "        Numpy array with the linear concept activation vector for a given concept\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sensitivity : (float32)\n",
    "        Sensitivity for inputted examples\n",
    "    '''\n",
    "    example = np.expand_dims(example, axis = 0)\n",
    "    model_f_activations = model_f.predict(example)[0]\n",
    "    model_f_activations.shape = (1, model_h.input_shape[1])\n",
    "    gradients = k.gradients(model_h.output, model_h.input)\n",
    "    gradient_func = k.function([model_h.input], gradients)\n",
    "    calc_grad = gradient_func([model_f_activations])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    return sensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f, model_h = return_split_models(model, 12)\n",
    "cav_vec = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f_activations = model_f.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_grad = gradient_func([model_f_activations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_grad = gradient_func([model_f_activations])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.dot(calc_grad, cav_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcav_score(x_train, y_train, model, layer, x_concept, y_concept):\n",
    "    ''' Returns the TCAV score for the training data to a given concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : (numpy.ndarray)\n",
    "        Training data where the i-th entry as x_train[i] is one example\n",
    "    y_train : (numpy.ndarray)\n",
    "        Training labels where the i-th entry as y_train[i] is one example\n",
    "    model : (keras.engine.sequential.Sequential)\n",
    "        Trained model to use\n",
    "    layer : (int)\n",
    "        Integer specifying layer to split model on\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tcav : (list)\n",
    "        TCAV score for given concept and class\n",
    "    '''\n",
    "    model_f, model_h = return_split_models(model, layer)\n",
    "    concept_cav = train_cav(model_f, x_concept, y_concept)\n",
    "    unique_labels = np.unique(y_train)\n",
    "    tcav = []\n",
    "    for label in unique_labels:\n",
    "        training_subset = x_train[np.array(y_train) == 1]\n",
    "        set_size = training_subset.shape[0]\n",
    "        count_of_sensitivity = 0\n",
    "        for example in training_subset:\n",
    "            sensitivity = conceptual_sensitivity(example, model_f, model_h, concept_cav)\n",
    "            print(sensitivity)\n",
    "            if sensitivity > 0:\n",
    "                count_of_sensitivity = count_of_sensitivity + 1\n",
    "        tcav.append(count_of_sensitivity/set_size)\n",
    "    return tcav\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcav_score(x_train, y_train, model, 12, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cav(model_f, x_concept, y_concept):\n",
    "    ''' Return the concept activation vector for the concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cav : (numpy.ndarray)\n",
    "        Concept activation vector\n",
    "    '''\n",
    "    concept_activations = model_f.predict(x_concept)\n",
    "    binary_classifier = Sequential()\n",
    "    binary_classifier.add(Dense(1, input_shape=concept_activations.shape[1:], activation='sigmoid'))\n",
    "    binary_classifier.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    binary_classifier.fit(concept_activations, y_concept, batch_size=32, epochs=20, shuffle=True)\n",
    "    cav = binary_classifier.layers[0].get_weights()[0]\n",
    "    return cav\n",
    "\n",
    "concept_cav = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conceptual_sensitivity(example, model_f, model_h, concept_cav):\n",
    "    ''' Return the conceptual conceptual sensitivity for a given example\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : (numpy.ndarray)\n",
    "        Example to calculate the concept sensitivity (be sure to reshape)\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Second Keras sequential model from return_split_models()\n",
    "    concept_cav : (numpy.ndarray)\n",
    "        Numpy array with the linear concept activation vector for a given concept\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sensitivity : (float32)\n",
    "        Sensitivity for inputted examples\n",
    "    '''\n",
    "    model_f_activations = model_f.predict(example)[0]\n",
    "    gradients = k.gradients(model_h.output, model_h.input)\n",
    "    gradient_func = k.function([model_h.input], gradients)\n",
    "    calc_grad = gradient_func([model_f_activations])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    return sensitivity\n",
    "\n",
    "conceptual_sensitivity(x_train[0], model_f, model_h, concept_cav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f = Sequential()\n",
    "model_f.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:], weights = model.layers[0].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(Conv2D(32, (3, 3), weights = model.layers[2].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_f.add(Dropout(0.25))\n",
    "\n",
    "model_f.add(Conv2D(64, (3, 3), padding='same', weights = model.layers[6].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(Conv2D(64, (3, 3), weights = model.layers[8].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_f.add(Flatten())\n",
    "\n",
    "acts = model_f.predict(x_train_concept)\n",
    "\n",
    "model_h = Sequential()\n",
    "model_h.add(Dense(512, input_shape=acts.shape[1:], weights = model.layers[13].get_weights()))\n",
    "model_h.add(Activation('relu'))\n",
    "model_h.add(Dropout(0.5))\n",
    "model_h.add(Dense(1, weights = model.layers[16].get_weights()))\n",
    "model_h.add(Activation('sigmoid'))\n",
    "\n",
    "concept_cav = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = x_train[np.array(y_train) == 1]\n",
    "\n",
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)\n",
    "pos_sens = 0\n",
    "list_sens = []\n",
    "for train_ex in training_subset:\n",
    "    example = train_ex.reshape((1, 32, 32, 3))\n",
    "    example_f = model_f.predict(example)[0].reshape((1,2304))\n",
    "    calc_grad = gradient_func([example_f])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    list_sens.append(sensitivity)\n",
    "    if sensitivity > 0:\n",
    "        pos_sens = pos_sens + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns, numpy as np\n",
    "ax = sns.distplot(list_sens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = x_train[np.array(y_train) == 0]\n",
    "i = 777\n",
    "example = training_subset[i].reshape((1, 32, 32, 3))\n",
    "example_f = model_f.predict(example)[0].reshape((1,2304))\n",
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)\n",
    "calc_grad = gradient_func([example_f])[0]\n",
    "sensitivity = np.dot(calc_grad, concept_cav)\n",
    "sensitivity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
