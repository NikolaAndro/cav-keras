{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pxenopoulos/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10, cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Utilities for concept activation vectors '''\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def return_split_models(model, layer):\n",
    "    ''' Split a model into model_f and model_h\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model to split\n",
    "    layer : (int)\n",
    "        Integer specifying layer to split model on\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the first part\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the second part\n",
    "    '''\n",
    "    model_f, model_h = Sequential(), Sequential()\n",
    "    for current_layer in range(0, layer+1):\n",
    "        model_f.add(model.layers[current_layer])\n",
    "    for current_layer in range(layer+1, len(model.layers)):\n",
    "        model_h.add(model.layers[current_layer])\n",
    "    return model_f, model_h\n",
    "\n",
    "def train_cav(model_f, x_concept, y_concept):\n",
    "    ''' Return the concept activation vector for the concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cav : (numpy.ndarray)\n",
    "        Concept activation vector\n",
    "    '''\n",
    "    concept_activations = model_f.predict(x_concept)\n",
    "    binary_classifier = Sequential()\n",
    "    binary_classifier.add(Dense(1, input_shape=concept_activations.shape[1:], activation='sigmoid'))\n",
    "    binary_classifier.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    binary_classifier.fit(concept_activations, y_concept, batch_size=32, epochs=20, shuffle=True)\n",
    "    cav = binary_concept_classifier.layers[0].get_weights()[0]\n",
    "    return cav\n",
    "\n",
    "def conceptual_sensitivity(example, model_f, model_h, concept_cav):\n",
    "    ''' Return the conceptual conceptual sensitivity for a given example\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : (numpy.ndarray)\n",
    "        Example to calculate the concept sensitivity (be sure to reshape)\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Second Keras sequential model from return_split_models()\n",
    "    concept_cav : (numpy.ndarray)\n",
    "        Numpy array with the linear concept activation vector for a given concept\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sensitivity : (float32)\n",
    "        Sensitivity for inputted examples\n",
    "    '''\n",
    "    model_f_activations = model_f.predict(example)[0]\n",
    "    gradients = k.gradients(model_h.output, model_h.input)\n",
    "    gradient_func = k.function([model_h.input], gradients)\n",
    "    calc_grad = gradient_func([model_f_activations])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    return sensitivity\n",
    "\n",
    "def tcav_score(x_train, y_train, model, layer, x_concept, y_concept):\n",
    "    ''' Returns the TCAV score for the training data to a given concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : (numpy.ndarray)\n",
    "        Training data where the i-th entry as x_train[i] is one example\n",
    "    y_train : (numpy.ndarray)\n",
    "        Training labels where the i-th entry as y_train[i] is one example\n",
    "    model : (keras.engine.sequential.Sequential)\n",
    "        Trained model to use\n",
    "    layer : (int)\n",
    "        Integer specifying layer to split model on\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tcav : (list)\n",
    "        TCAV score for given concept and class\n",
    "    '''\n",
    "    model_f, model_h = return_split_models(model, layer)\n",
    "    concept_cav = train_cav(model_f, x_concept, y_concept)\n",
    "    unique_labels = np.unique(y_train)\n",
    "    tcav = []\n",
    "    for label in unique_labels:\n",
    "        training_subset = x_train[np.array(y_train) == 1]\n",
    "        set_size = training_subset.shape[0]\n",
    "        count_of_sensitivity = 0\n",
    "        for example in training_subset:\n",
    "            sensitivity = conceptual_sensitivity(example, model_f, model_h, concept_cav)\n",
    "            if sensitivity > 0:\n",
    "                count_of_sensitivity = count_of_sensitivity + 1\n",
    "        tcav.append(count_of_sensitivity/set_size)\n",
    "    return tcav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "batch_size = 32\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Keep airplanes (0) and ships (8) from CIFAR-10\n",
    "airplanes = y_train == [0]\n",
    "ships = y_train == [8]\n",
    "indices = airplanes + ships\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train = x_train[indx_to_use]\n",
    "y_train = y_train[indx_to_use]\n",
    "\n",
    "y_train = (y_train == 8).astype(int)\n",
    "y_train = np.concatenate(y_train).ravel().tolist()\n",
    "\n",
    "# Ships are now 1, airplanes are 0\n",
    "\n",
    "# keep cloud (50) and sea (54) from CIFAR-100\n",
    "(x_train_concept, y_train_concept), (x_test_concept, y_test_concept) = cifar100.load_data()\n",
    "\n",
    "other = y_train_concept == [47]\n",
    "concept = y_train_concept == [54]\n",
    "indices = other + concept\n",
    "indx_to_use = [i for i, x in enumerate(indices) if x]\n",
    "\n",
    "x_train_concept = x_train_concept[indx_to_use]\n",
    "y_train_concept = y_train_concept[indx_to_use]\n",
    "y_train_concept = (y_train_concept == 54).astype(int)\n",
    "y_train_concept = np.concatenate(y_train_concept).ravel().tolist()\n",
    "# Sea is now 1, clouds are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 28s 3ms/step - loss: 0.5880 - acc: 0.6788\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 0.4278 - acc: 0.8102\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 0.3391 - acc: 0.8517\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# initiate optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "# train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "model.save_weights(\"test_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Utilities for concept activation vectors '''\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def return_split_models(model, layer):\n",
    "    ''' Split a model into model_f and model_h\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model to split\n",
    "    layer : (int)\n",
    "        Integer specifying layer to split model on\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the first part\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Keras sequential model that is the second part\n",
    "    '''\n",
    "    model_f, model_h = Sequential(), Sequential()\n",
    "    for current_layer in range(0, layer+1):\n",
    "        model_f.add(model.layers[current_layer])\n",
    "    # Write input layer for model_h\n",
    "    model_h.add(InputLayer(input_shape=model.layers[layer+1].input_shape[1:]))\n",
    "    for current_layer in range(layer+1, len(model.layers)):\n",
    "        model_h.add(model.layers[current_layer])\n",
    "    return model_f, model_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f, model_h = return_split_models(model, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "=================================================================\n",
      "Total params: 65,568\n",
      "Trainable params: 65,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = model_f.predict(x_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 221us/step - loss: 2.0616 - acc: 0.7110\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.9360 - acc: 0.8420\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.5940 - acc: 0.8770\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.5007 - acc: 0.8940\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.3427 - acc: 0.8990\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.3936 - acc: 0.9080\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.2499 - acc: 0.9330\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.3914 - acc: 0.9030\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.2228 - acc: 0.9420\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1186 - acc: 0.9620\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.1420 - acc: 0.9590\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0858 - acc: 0.9680\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0846 - acc: 0.9690\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.2293 - acc: 0.9380\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0617 - acc: 0.9760\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0612 - acc: 0.9760\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.1944 - acc: 0.9430\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0479 - acc: 0.9810\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.1267 - acc: 0.9520\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0502 - acc: 0.9830\n"
     ]
    }
   ],
   "source": [
    "def train_cav(model_f, x_concept, y_concept):\n",
    "    ''' Return the concept activation vector for the concept\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    x_concept : (numpy.ndarray)\n",
    "        Training data for concept set, has same size as model training data\n",
    "    y_concept : (numpy.ndarray)\n",
    "        Labels for concept set, has same size as model training labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cav : (numpy.ndarray)\n",
    "        Concept activation vector\n",
    "    '''\n",
    "    concept_activations = model_f.predict(x_concept)\n",
    "    binary_classifier = Sequential()\n",
    "    binary_classifier.add(Dense(1, input_shape=concept_activations.shape[1:], activation='sigmoid'))\n",
    "    binary_classifier.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    binary_classifier.fit(concept_activations, y_concept, batch_size=32, epochs=20, shuffle=True)\n",
    "    cav = binary_classifier.layers[0].get_weights()[0]\n",
    "    return cav\n",
    "\n",
    "concept_cav = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (32, 32, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-69f52f7b5eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mconceptual_sensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcept_cav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-69f52f7b5eba>\u001b[0m in \u001b[0;36mconceptual_sensitivity\u001b[0;34m(example, model_f, model_h, concept_cav)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mSensitivity\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minputted\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     '''\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel_f_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mgradient_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (32, 32, 3)"
     ]
    }
   ],
   "source": [
    "def conceptual_sensitivity(example, model_f, model_h, concept_cav):\n",
    "    ''' Return the conceptual conceptual sensitivity for a given example\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : (numpy.ndarray)\n",
    "        Example to calculate the concept sensitivity (be sure to reshape)\n",
    "    model_f : (keras.engine.sequential.Sequential)\n",
    "        First Keras sequential model from return_split_models()\n",
    "    model_h : (keras.engine.sequential.Sequential)\n",
    "        Second Keras sequential model from return_split_models()\n",
    "    concept_cav : (numpy.ndarray)\n",
    "        Numpy array with the linear concept activation vector for a given concept\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sensitivity : (float32)\n",
    "        Sensitivity for inputted examples\n",
    "    '''\n",
    "    model_f_activations = model_f.predict(example)[0]\n",
    "    gradients = k.gradients(model_h.output, model_h.input)\n",
    "    gradient_func = k.function([model_h.input], gradients)\n",
    "    calc_grad = gradient_func([model_f_activations])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    return sensitivity\n",
    "\n",
    "conceptual_sensitivity(x_train[0], model_f, model_h, concept_cav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04790389, 0.        , 0.        , ..., 0.3659242 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.212491  , 0.        , 0.        , ..., 0.18722388, 0.        ,\n",
       "        0.28412533],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.10809718],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.04549147, 0.        ,\n",
       "        0.        ],\n",
       "       [0.10371948, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.04492123],\n",
       "       [0.01309306, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_f.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5254902 , 0.7294118 , 0.8745098 ],\n",
       "        [0.5137255 , 0.72156864, 0.8627451 ],\n",
       "        [0.5019608 , 0.7137255 , 0.85490197],\n",
       "        ...,\n",
       "        [0.49803922, 0.70980394, 0.87058824],\n",
       "        [0.49803922, 0.70980394, 0.87058824],\n",
       "        [0.5019608 , 0.7137255 , 0.8745098 ]],\n",
       "\n",
       "       [[0.52156866, 0.7411765 , 0.89411765],\n",
       "        [0.5058824 , 0.7294118 , 0.8784314 ],\n",
       "        [0.5019608 , 0.7294118 , 0.8784314 ],\n",
       "        ...,\n",
       "        [0.49803922, 0.7176471 , 0.8784314 ],\n",
       "        [0.49803922, 0.7176471 , 0.8784314 ],\n",
       "        [0.5019608 , 0.72156864, 0.88235295]],\n",
       "\n",
       "       [[0.5019608 , 0.7254902 , 0.8862745 ],\n",
       "        [0.49803922, 0.7137255 , 0.8745098 ],\n",
       "        [0.5019608 , 0.7137255 , 0.8745098 ],\n",
       "        ...,\n",
       "        [0.49411765, 0.70980394, 0.87058824],\n",
       "        [0.49411765, 0.70980394, 0.87058824],\n",
       "        [0.49411765, 0.7058824 , 0.8666667 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.68235296, 0.8156863 , 0.92156863],\n",
       "        [0.67058825, 0.80784315, 0.8980392 ],\n",
       "        [0.60784316, 0.7411765 , 0.84705883],\n",
       "        ...,\n",
       "        [0.10588235, 0.36862746, 0.53333336],\n",
       "        [0.11372549, 0.3764706 , 0.5372549 ],\n",
       "        [0.10980392, 0.36862746, 0.53333336]],\n",
       "\n",
       "       [[0.7607843 , 0.8666667 , 0.95686275],\n",
       "        [0.7411765 , 0.84313726, 0.9372549 ],\n",
       "        [0.62352943, 0.76862746, 0.88235295],\n",
       "        ...,\n",
       "        [0.11764706, 0.37254903, 0.5411765 ],\n",
       "        [0.11764706, 0.3764706 , 0.54509807],\n",
       "        [0.11764706, 0.37254903, 0.54901963]],\n",
       "\n",
       "       [[0.75686276, 0.8509804 , 0.92941177],\n",
       "        [0.70980394, 0.8156863 , 0.9019608 ],\n",
       "        [0.65882355, 0.7882353 , 0.8901961 ],\n",
       "        ...,\n",
       "        [0.12156863, 0.36862746, 0.53333336],\n",
       "        [0.1254902 , 0.36862746, 0.5372549 ],\n",
       "        [0.1254902 , 0.36862746, 0.5411765 ]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f = Sequential()\n",
    "model_f.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:], weights = model.layers[0].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(Conv2D(32, (3, 3), weights = model.layers[2].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_f.add(Dropout(0.25))\n",
    "\n",
    "model_f.add(Conv2D(64, (3, 3), padding='same', weights = model.layers[6].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(Conv2D(64, (3, 3), weights = model.layers[8].get_weights()))\n",
    "model_f.add(Activation('relu'))\n",
    "model_f.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_f.add(Flatten())\n",
    "\n",
    "acts = model_f.predict(x_train_concept)\n",
    "\n",
    "model_h = Sequential()\n",
    "model_h.add(Dense(512, input_shape=acts.shape[1:], weights = model.layers[13].get_weights()))\n",
    "model_h.add(Activation('relu'))\n",
    "model_h.add(Dropout(0.5))\n",
    "model_h.add(Dense(1, weights = model.layers[16].get_weights()))\n",
    "model_h.add(Activation('sigmoid'))\n",
    "\n",
    "concept_cav = train_cav(model_f, x_train_concept, y_train_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = x_train[np.array(y_train) == 1]\n",
    "\n",
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)\n",
    "pos_sens = 0\n",
    "list_sens = []\n",
    "for train_ex in training_subset:\n",
    "    example = train_ex.reshape((1, 32, 32, 3))\n",
    "    example_f = model_f.predict(example)[0].reshape((1,2304))\n",
    "    calc_grad = gradient_func([example_f])[0]\n",
    "    sensitivity = np.dot(calc_grad, concept_cav)\n",
    "    list_sens.append(sensitivity)\n",
    "    if sensitivity > 0:\n",
    "        pos_sens = pos_sens + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns, numpy as np\n",
    "ax = sns.distplot(list_sens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = x_train[np.array(y_train) == 0]\n",
    "i = 777\n",
    "example = training_subset[i].reshape((1, 32, 32, 3))\n",
    "example_f = model_f.predict(example)[0].reshape((1,2304))\n",
    "gradients = k.gradients(model_h.output, model_h.input)\n",
    "gradient_func = k.function([model_h.input], gradients)\n",
    "calc_grad = gradient_func([example_f])[0]\n",
    "sensitivity = np.dot(calc_grad, concept_cav)\n",
    "sensitivity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
